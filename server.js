require('dotenv').config();
const express = require('express');
const cors = require('cors');
const { Connection, PublicKey, LAMPORTS_PER_SOL, Transaction, SystemProgram, sendAndConfirmTransaction } = require('@solana/web3.js');
const { Program, AnchorProvider, Wallet, BN } = require('@coral-xyz/anchor');
const bs58 = require('bs58');
const fs = require('fs');
const path = require('path');
const sqlite3 = require('sqlite3').verbose();
const { open } = require('sqlite');
const axios = require('axios');
const FormData = require('form-data');
const { Queue, Worker } = require('bullmq');
const IORedis = require('ioredis');

// --- Moderation Deps ---
const tf = require('@tensorflow/tfjs-node');
const nsfw = require('nsfwjs');
const jpeg = require('jpeg-js');
const png = require('pngjs').PNG;

// --- Config ---
const VERSION = "v10.3.1";
const PORT = process.env.PORT || 3000;
const HELIUS_API_KEY = process.env.HELIUS_API_KEY;
const DEV_WALLET_PRIVATE_KEY = process.env.DEV_WALLET_PRIVATE_KEY;
const PINATA_JWT = process.env.PINATA_JWT;
// Default to localhost if not provided, but warn
const REDIS_URL = process.env.REDIS_URL || 'redis://127.0.0.1:6379'; 
const HEADER_IMAGE_URL = process.env.HEADER_IMAGE_URL || "https://placehold.co/60x60/d97706/ffffff?text=LOGO";

const TARGET_PUMP_TOKEN = new PublicKey("pumpCmXqMfrsAkQ5r49WcJnRayYRqmXz6ae8H7H9Dfn");
const WALLET_19_5 = new PublicKey("9Cx7bw3opoGJ2z9uYbMLcfb1ukJbJN4CP5uBbDvWwu7Z");
const WALLET_0_5 = new PublicKey("9zT9rFzDA84K6hJJibcy9QjaFmM8Jm2LzdrvXEiBSq9g");
const FEE_THRESHOLD_SOL = 0.20;
const PUMP_PROGRAM_ID = new PublicKey("6EF8rrecthR5Dkzon8Nwu78hRvfCKubJ14M5uBEwF6P");
const TOKEN_PROGRAM_2022_ID = new PublicKey("TokenzQdBNbLqP5VEhdkAS6EPFLC1PHnBqCXEpPxuEb");
const ASSOCIATED_TOKEN_PROGRAM_ID = new PublicKey("ATokenGPvbdGVxr1b2hvZbsiqW5xWH25efTNsLJA8knL");
const FEE_PROGRAM_ID = new PublicKey("pfeeUxB6jkeY1Hxd7CsFCAjcbHA9rWtchMGdZ6VojVZ");
const FEE_RECIPIENT = new PublicKey("FNLWHjvjptwC7LxycdK3Knqcv5ptC19C9rynn6u2S1tB");
const PUMP_LIQUIDITY_WALLET = "CJXSGQnTeRRGbZE1V4rQjYDeKLExPnxceczmAbgBdTsa";

// --- DB & Directories ---
const DISK_ROOT = '/var/data';
const DATA_DIR = path.join(DISK_ROOT, 'tokens');
const DEBUG_LOG_FILE = path.join(DISK_ROOT, 'server_debug.log');

if (!fs.existsSync(DISK_ROOT)) { if (!fs.existsSync('./data')) fs.mkdirSync('./data'); }
const DB_PATH = fs.existsSync(DISK_ROOT) ? path.join(DISK_ROOT, 'launcher.db') : './data/launcher.db';
const ACTIVE_DATA_DIR = fs.existsSync(DISK_ROOT) ? DATA_DIR : './data/tokens';
const ensureDir = (dir) => { if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true }); };
ensureDir(ACTIVE_DATA_DIR);

// --- LOGGER ---
const logStream = fs.createWriteStream(DEBUG_LOG_FILE, { flags: 'a' });
function log(level, message, meta = {}) {
    const timestamp = new Date().toISOString();
    const metaString = Object.keys(meta).length ? JSON.stringify(meta) : '';
    const logLine = `[${timestamp}] [${level.toUpperCase()}] ${message} ${metaString}\n`;
    logStream.write(logLine);
    const consoleMethod = level === 'error' ? console.error : console.log;
    consoleMethod(`[${level.toUpperCase()}] ${message}`, metaString ? meta : '');
}
const logger = {
    info: (msg, meta) => log('info', msg, meta),
    warn: (msg, meta) => log('warn', msg, meta),
    error: (msg, meta) => log('error', msg, meta)
};

// --- REDIS SETUP WITH RETRY & ERROR HANDLING ---
let deployQueue;
let redisConnection;

try {
    redisConnection = new IORedis(REDIS_URL, {
        maxRetriesPerRequest: null,
        enableReadyCheck: false, // Helps with some cloud Redis providers
        retryStrategy: (times) => Math.min(times * 50, 2000) // Retry connection
    });

    redisConnection.on('error', (err) => {
        logger.error("Redis Connection Error", { msg: err.message });
    });

    deployQueue = new Queue('deployQueue', { connection: redisConnection });
    logger.info("✅ Redis Queue Initialized");

} catch (e) {
    logger.error("❌ Failed to initialize Redis Queue", { error: e.message });
    // We proceed, but the deploy endpoint will need to handle the missing queue
}

// --- DB ---
let db;
async function initDB() {
    db = await open({ filename: DB_PATH, driver: sqlite3.Database });
    await db.exec(`
        CREATE TABLE IF NOT EXISTS tokens (mint TEXT PRIMARY KEY, userPubkey TEXT, name TEXT, ticker TEXT, description TEXT, twitter TEXT, website TEXT, image TEXT, isMayhemMode BOOLEAN, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP, volume24h REAL DEFAULT 0, marketCap REAL DEFAULT 0, lastUpdated INTEGER DEFAULT 0);
        CREATE TABLE IF NOT EXISTS transactions (signature TEXT PRIMARY KEY, userPubkey TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP);
        CREATE TABLE IF NOT EXISTS logs (id INTEGER PRIMARY KEY AUTOINCREMENT, type TEXT, data TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP);
        CREATE TABLE IF NOT EXISTS stats (key TEXT PRIMARY KEY, value REAL);
        CREATE TABLE IF NOT EXISTS token_holders (mint TEXT, holderPubkey TEXT, rank INTEGER, lastUpdated INTEGER, PRIMARY KEY (mint, holderPubkey));
        INSERT OR IGNORE INTO stats (key, value) VALUES ('accumulatedFeesLamports', 0);
        INSERT OR IGNORE INTO stats (key, value) VALUES ('lifetimeFeesLamports', 0);
        INSERT OR IGNORE INTO stats (key, value) VALUES ('totalPumpBoughtLamports', 0);
    `);
    logger.info(`DB Initialized at ${DB_PATH}`);
}

// --- MODERATION SETUP ---
let _model;
async function loadModel() {
    if (_model) return _model;
    logger.info("Loading NSFWJS Model...");
    try {
        _model = await nsfw.load(); 
        logger.info("Model Loaded.");
        return _model;
    } catch(e) {
        logger.error("Failed to load NSFW Model", {err:e.message});
        return null; // Allow fail-open if model fails to load? Or closed.
    }
}
async function imageToTensor(buffer, mimeType) {
    let pixels;
    if (mimeType === 'image/jpeg' || mimeType === 'image/jpg') pixels = jpeg.decode(buffer, true);
    else if (mimeType === 'image/png') pixels = png.sync.read(buffer);
    else throw new Error("Unsupported image type");
    const numChannels = 3; const numPixels = pixels.width * pixels.height; const values = new Int32Array(numPixels * numChannels);
    for (let i = 0; i < numPixels; i++) { for (let c = 0; c < numChannels; c++) { values[i * numChannels + c] = pixels.data[i * 4 + c]; } }
    return tf.tensor3d(values, [pixels.height, pixels.width, numChannels], 'int32');
}
async function checkContentSafety(base64Data) {
    try {
        const model = await loadModel();
        if (!model) return true; // Fail open if model broken
        
        const matches = base64Data.match(/^data:([A-Za-z-+\/]+);base64,(.+)$/);
        if (!matches || matches.length !== 3) return false; 
        const mimeType = matches[1]; const buffer = Buffer.from(matches[2], 'base64');
        
        // Basic check for known image types
        if (!['image/png', 'image/jpeg', 'image/jpg'].includes(mimeType)) return false;

        const image = await imageToTensor(buffer, mimeType);
        const predictions = await model.classify(image);
        image.dispose(); 
        const unsafe = predictions.find(p => (p.className === 'Porn' || p.className === 'Hentai') && p.probability > 0.80);
        if (unsafe) { logger.warn(`Blocked unsafe content: ${unsafe.className}`); return false; }
        return true;
    } catch (e) { logger.error("Moderation Error", {err:e.message}); return true; }
}

initDB();
loadModel();

const app = express();
app.use(cors());
app.use(express.json({ limit: '50mb' }));

const connection = new Connection(`https://mainnet.helius-rpc.com/?api-key=${HELIUS_API_KEY}`, "confirmed");
const devKeypair = require('@solana/web3.js').Keypair.fromSecretKey(bs58.decode(DEV_WALLET_PRIVATE_KEY));
const wallet = new Wallet(devKeypair);
const provider = new AnchorProvider(connection, wallet, { commitment: "confirmed" });
const idlRaw = fs.readFileSync('./pump_idl.json', 'utf8');
const idl = JSON.parse(idlRaw);
idl.address = PUMP_PROGRAM_ID.toString();
const program = new Program(idl, PUMP_PROGRAM_ID, provider);

// --- Helpers ---
async function sendTxWithRetry(tx, signers, retries = 5) { 
    for (let i = 0; i < retries; i++) {
        try {
            const { blockhash, lastValidBlockHeight } = await connection.getLatestBlockhash('finalized');
            tx.recentBlockhash = blockhash; tx.lastValidBlockHeight = lastValidBlockHeight;
            const sig = await sendAndConfirmTransaction(connection, tx, signers, { commitment: 'confirmed', skipPreflight: true });
            return sig;
        } catch (err) {
            if (i === retries - 1) throw err;
            await new Promise(r => setTimeout(r, 2000 * Math.pow(1.5, i))); 
        }
    }
}
async function addFees(amt) { if(db) { await db.run('UPDATE stats SET value = value + ? WHERE key = ?', [amt, 'accumulatedFeesLamports']); await db.run('UPDATE stats SET value = value + ? WHERE key = ?', [amt, 'lifetimeFeesLamports']); }}
async function addPumpBought(amt) { if(db) await db.run('UPDATE stats SET value = value + ? WHERE key = ?', [amt, 'totalPumpBoughtLamports']); }
async function getTotalLaunches() { if(!db) return 0; const res = await db.get('SELECT COUNT(*) as count FROM tokens'); return res ? res.count : 0; }
async function getStats() { if(!db) return { accumulatedFeesLamports: 0, lifetimeFeesLamports: 0, totalPumpBoughtLamports: 0 }; const acc = await db.get('SELECT value FROM stats WHERE key = ?', 'accumulatedFeesLamports'); const life = await db.get('SELECT value FROM stats WHERE key = ?', 'lifetimeFeesLamports'); const pump = await db.get('SELECT value FROM stats WHERE key = ?', 'totalPumpBoughtLamports'); return { accumulatedFeesLamports: acc ? acc.value : 0, lifetimeFeesLamports: life ? life.value : 0, totalPumpBoughtLamports: pump ? pump.value : 0 }; }
async function resetAccumulatedFees(used) { const cur = await db.get('SELECT value FROM stats WHERE key = ?', 'accumulatedFeesLamports'); await db.run('UPDATE stats SET value = ? WHERE key = ?', [Math.max(0, (cur ? cur.value : 0) - used), 'accumulatedFeesLamports']); }
async function logPurchase(type, data) { try { await db.run('INSERT INTO logs (type, data) VALUES (?, ?)', [type, JSON.stringify(data)]); } catch (e) {} }
async function getRecentLogs(limit=5) { const rows = await db.all('SELECT * FROM logs ORDER BY id DESC LIMIT ?', limit); return rows.map(row => ({ ...JSON.parse(row.data), type: row.type, timestamp: row.timestamp })); }
async function saveTokenData(pk, mint, meta) { try { await db.run(`INSERT INTO tokens (mint, userPubkey, name, ticker, description, twitter, website, image, isMayhemMode) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)`, [mint, pk, meta.name, meta.ticker, meta.description, meta.twitter, meta.website, meta.image, meta.isMayhemMode]); const shard = pk.slice(0, 2).toLowerCase(); const dir = path.join(ACTIVE_DATA_DIR, shard); ensureDir(dir); fs.writeFileSync(path.join(dir, `${mint}.json`), JSON.stringify({ userPubkey: pk, mint, metadata: meta, timestamp: new Date().toISOString() }, null, 2)); } catch (e) { logger.error("Save Token Error", {err:e.message}); } }
async function checkTransactionUsed(sig) { const res = await db.get('SELECT signature FROM transactions WHERE signature = ?', sig); return !!res; }
async function markTransactionUsed(sig, pk) { await db.run('INSERT INTO transactions (signature, userPubkey) VALUES (?, ?)', [sig, pk]); }

// --- WORKER DEFINITION ---
// Only start worker if Redis is connected
let worker;
if (redisConnection) {
    worker = new Worker('deployQueue', async (job) => {
        logger.info(`Processing Job ${job.id}: ${job.data.ticker}`);
        const { name, ticker, description, twitter, website, image, userPubkey, isMayhemMode } = job.data;

        // 1. Moderation Check
        const isSafe = await checkContentSafety(image);
        if (!isSafe) {
            throw new Error("Upload blocked: NSFW/Illegal content detected.");
        }

        // 2. Upload Metadata
        let metadataUri;
        try { metadataUri = await uploadMetadataToPinata(name, ticker, description, twitter, website, image); }
        catch(e) { throw new Error("Metadata upload failed"); }

        // 3. Blockchain Tx
        const mintKeypair = Keypair.generate();
        const mint = mintKeypair.publicKey;
        const creator = devKeypair.publicKey;

        const { mintAuthority, bondingCurve, global, eventAuthority, globalVolume, userVolume, feeConfig, creatorVault } = getDeploymentPDAs(mint, creator);
        const { globalParams, solVault, mayhemState } = getMayhemPDAs(mint);
        const associatedBondingCurve = getATA(mint, bondingCurve);
        const mayhemTokenVault = getATA(mint, solVault);
        const associatedUser = getATA(mint, creator);

        const createIx = await program.methods.createV2(name, ticker, metadataUri, creator, !!isMayhemMode).accounts({ mint, mintAuthority, bondingCurve, associatedBondingCurve, global, user: creator, systemProgram: SystemProgram.programId, tokenProgram: TOKEN_PROGRAM_2022_ID, associatedTokenProgram: ASSOCIATED_TOKEN_PROGRAM_ID, mayhemProgramId: MAYHEM_PROGRAM_ID, globalParams, solVault, mayhemState, mayhemTokenVault, eventAuthority, program: PUMP_PROGRAM_ID }).instruction();
        const buyIx = await program.methods.buyExactSolIn(new BN(0.01 * LAMPORTS_PER_SOL), new BN(1), false).accounts({ global, feeRecipient: FEE_RECIPIENT, mint, bondingCurve, associatedBondingCurve, associatedUser, user: devKeypair.publicKey, systemProgram: SystemProgram.programId, tokenProgram: TOKEN_PROGRAM_2022_ID, creatorVault, eventAuthority, program: PUMP_PROGRAM_ID, globalVolumeAccumulator: globalVolume, userVolumeAccumulator: userVolume, feeConfig, feeProgram: FEE_PROGRAM_ID }).instruction();

        const tx = new Transaction().add(createIx).add(buyIx);
        tx.feePayer = creator;
        const sig = await sendTxWithRetry(tx, [devKeypair, mintKeypair]);
        
        // 4. Save Data
        await saveTokenData(userPubkey, mint.toString(), { name, ticker, description, twitter, website, image, isMayhemMode });

        // 5. Schedule Sell
        setTimeout(async () => { try { const bal = await connection.getTokenAccountBalance(associatedUser); if (bal.value.uiAmount > 0) { const sellIx = await program.methods.sell(new BN(bal.value.amount), new BN(0)).accounts({ global, feeRecipient: FEE_RECIPIENT, mint, bondingCurve, associatedBondingCurve, associatedUser, user: creator, systemProgram: SystemProgram.programId, tokenProgram: TOKEN_PROGRAM_2022_ID, associatedTokenProgram: ASSOCIATED_TOKEN_PROGRAM_ID, creatorVault, eventAuthority, program: PUMP_PROGRAM_ID, globalVolumeAccumulator: globalVolume, userVolumeAccumulator: userVolume, feeConfig, feeProgram: FEE_PROGRAM_ID }).instruction(); const sellTx = new Transaction().add(sellIx); await sendTxWithRetry(sellTx, [devKeypair]); } } catch (e) { logger.error("Sell error", {msg: e.message}); } }, 1500); 

        return { mint: mint.toString(), signature: sig };
    }, { 
        connection: redisConnection, 
        concurrency: 1 
    });
}

// --- PDAs/Uploads (Unchanged) ---
function getPumpPDAs(mint, programId = PUMP_PROGRAM_ID) {
    const [bondingCurve] = PublicKey.findProgramAddressSync([Buffer.from("bonding-curve"), mint.toBuffer()], programId);
    const associatedBondingCurve = PublicKey.findProgramAddressSync([bondingCurve.toBuffer(), TOKEN_PROGRAM_2022_ID.toBuffer(), mint.toBuffer()], ASSOCIATED_TOKEN_PROGRAM_ID)[0];
    return { bondingCurve, associatedBondingCurve };
}
function getDeploymentPDAs(mint, creator) {
    const [mintAuthority] = PublicKey.findProgramAddressSync([Buffer.from("mint-authority")], PUMP_PROGRAM_ID);
    const [bondingCurve] = PublicKey.findProgramAddressSync([Buffer.from("bonding-curve"), mint.toBuffer()], PUMP_PROGRAM_ID);
    const [global] = PublicKey.findProgramAddressSync([Buffer.from("global")], PUMP_PROGRAM_ID);
    const [eventAuthority] = PublicKey.findProgramAddressSync([Buffer.from("__event_authority")], PUMP_PROGRAM_ID);
    const [globalVolume] = PublicKey.findProgramAddressSync([Buffer.from("global_volume_accumulator")], PUMP_PROGRAM_ID);
    const [userVolume] = PublicKey.findProgramAddressSync([Buffer.from("user_volume_accumulator"), creator.toBuffer()], PUMP_PROGRAM_ID);
    const [feeConfig] = PublicKey.findProgramAddressSync([Buffer.from("fee_config")], FEE_PROGRAM_ID);
    const [creatorVault] = PublicKey.findProgramAddressSync([Buffer.from("creator-vault"), creator.toBuffer()], PUMP_PROGRAM_ID);
    return { mintAuthority, bondingCurve, global, eventAuthority, globalVolume, userVolume, feeConfig, creatorVault };
}
function getMayhemPDAs(mint) {
    const [globalParams] = PublicKey.findProgramAddressSync([Buffer.from("global-params")], MAYHEM_PROGRAM_ID);
    const [solVault] = PublicKey.findProgramAddressSync([Buffer.from("sol-vault")], MAYHEM_PROGRAM_ID);
    const [mayhemState] = PublicKey.findProgramAddressSync([Buffer.from("mayhem-state"), mint.toBuffer()], MAYHEM_PROGRAM_ID);
    return { globalParams, solVault, mayhemState };
}
function getATA(mint, owner) { return PublicKey.findProgramAddressSync([owner.toBuffer(), TOKEN_PROGRAM_2022_ID.toBuffer(), mint.toBuffer()], ASSOCIATED_TOKEN_PROGRAM_ID)[0]; }
async function uploadImageToPinata(b64) { try { const b=Buffer.from(b64.split(',')[1],'base64'); const f=new FormData(); f.append('file',b,{filename:'i.png'}); const r=await axios.post('https://api.pinata.cloud/pinning/pinFileToIPFS',f,{headers:{'Authorization':`Bearer ${PINATA_JWT}`,...f.getHeaders()}}); return `https://gateway.pinata.cloud/ipfs/${r.data.IpfsHash}`; } catch(e){ return "https://gateway.pinata.cloud/ipfs/QmPc5gX8W8h9j5h8x8h8h8h8h8h8h8h8h8h8h8h8h8"; } }
async function uploadMetadataToPinata(n,s,d,t,w,i) { let u="https://gateway.pinata.cloud/ipfs/QmPc5gX8W8h9j5h8x8h8h8h8h8h8h8h8h8h8h8h8h8"; if(i) u=await uploadImageToPinata(i); const m={name:n,symbol:s,description:d,image:u,extensions:{twitter:t,website:w}}; try { const r=await axios.post('https://api.pinata.cloud/pinning/pinJSONToIPFS',m,{headers:{'Authorization':`Bearer ${PINATA_JWT}`}}); return `https://gateway.pinata.cloud/ipfs/${r.data.IpfsHash}`; } catch(e) { throw new Error("Failed to upload metadata"); } }

// --- Routes ---
app.get('/api/version', (req, res) => res.json({ version: VERSION }));
app.get('/api/health', async (req, res) => {
    try {
        const stats = await getStats();
        const launches = await getTotalLaunches();
        const logs = await db.all('SELECT * FROM logs ORDER BY id DESC LIMIT 50'); 
        res.json({ status: "online", wallet: devKeypair.publicKey.toString(), lifetimeFees: (stats.lifetimeFeesLamports / LAMPORTS_PER_SOL).toFixed(4), totalPumpBought: (stats.totalPumpBoughtLamports / LAMPORTS_PER_SOL).toFixed(4), totalLaunches: launches, recentLogs: logs.map(l => ({ ...JSON.parse(l.data), type: l.type, timestamp: l.timestamp })), headerImageUrl: HEADER_IMAGE_URL });
    } catch (e) { res.status(500).json({ error: "DB Error" }); }
});
app.get('/api/check-holder', async (req, res) => {
    const { userPubkey } = req.query; if (!userPubkey) return res.json({ isHolder: false });
    try { const result = await db.get('SELECT mint, rank FROM token_holders WHERE holderPubkey = ? LIMIT 1', userPubkey); res.json({ isHolder: !!result, ...(result || {}) }); } catch (e) { res.status(500).json({ error: "DB Error" }); }
});
app.get('/api/leaderboard', async (req, res) => {
    const { userPubkey } = req.query;
    try {
        const rows = await db.all('SELECT * FROM tokens ORDER BY volume24h DESC LIMIT 10');
        const leaderboard = await Promise.all(rows.map(async (r) => {
            let isUserTopHolder = false;
            if (userPubkey) { const holderEntry = await db.get('SELECT rank FROM token_holders WHERE mint = ? AND holderPubkey = ?', [r.mint, userPubkey]); if (holderEntry) isUserTopHolder = true; }
            return { mint: r.mint, name: r.name, ticker: r.ticker, image: r.image, price: (r.marketCap / 1000000000).toFixed(6), volume: r.volume24h, isUserTopHolder };
        }));
        res.json(leaderboard);
    } catch (e) { res.status(500).json([]); }
});
app.get('/api/recent-launches', async (req, res) => { try { const rows = await db.all('SELECT userPubkey, ticker, mint, timestamp FROM tokens ORDER BY timestamp DESC LIMIT 10'); res.json(rows.map(r => ({ userSnippet: r.userPubkey.slice(0, 5), ticker: r.ticker, mint: r.mint }))); } catch (e) { res.status(500).json([]); } });
app.get('/api/debug/logs', (req, res) => { const logPath = path.join(DISK_ROOT, 'server_debug.log'); if (fs.existsSync(logPath)) { const stats = fs.statSync(logPath); const stream = fs.createReadStream(logPath, { start: Math.max(0, stats.size - 50000) }); stream.pipe(res); } else { res.send("No logs yet."); } });
app.get('/api/job-status/:id', async (req, res) => {
    if (!deployQueue) return res.status(500).json({ error: "Queue not initialized (Redis missing?)" });
    const job = await deployQueue.getJob(req.params.id);
    if (!job) return res.status(404).json({ error: "Job not found" });
    const state = await job.getState();
    res.json({ id: job.id, state, result: job.returnvalue, failedReason: job.failedReason });
});

app.post('/api/deploy', async (req, res) => {
    try {
        const { name, ticker, description, twitter, website, userTx, userPubkey, image, isMayhemMode } = req.body;
        if (!name || name.length > 32) return res.status(400).json({ error: "Invalid Name" });
        if (!ticker || ticker.length > 10) return res.status(400).json({ error: "Invalid Ticker" });
        if (!image) return res.status(400).json({ error: "Image required" });

        const used = await checkTransactionUsed(userTx);
        if (used) return res.status(400).json({ error: "Transaction signature already used." });

        const txInfo = await connection.getParsedTransaction(userTx, { commitment: "confirmed", maxSupportedTransactionVersion: 0 });
        if (!txInfo) return res.status(400).json({ error: "Transaction not found." });
        const validPayment = txInfo.transaction.message.instructions.some(ix => { if (ix.programId.toString() !== '11111111111111111111111111111111') return false; if (ix.parsed.type !== 'transfer') return false; return ix.parsed.info.destination === devKeypair.publicKey.toString() && ix.parsed.info.lamports >= 0.05 * LAMPORTS_PER_SOL; });
        if (!validPayment) return res.status(400).json({ error: "Payment verification failed." });

        await markTransactionUsed(userTx, userPubkey);
        await addFees(0.05 * LAMPORTS_PER_SOL);

        // Add to Queue
        if (!deployQueue) return res.status(500).json({ error: "Deployment Queue Unavailable" });
        const job = await deployQueue.add('deployToken', { name, ticker, description, twitter, website, image, userPubkey, isMayhemMode });
        res.json({ success: true, jobId: job.id, message: "Queued" });
    } catch (err) { logger.error("Deploy Request Error", {error: err.message}); res.status(500).json({ error: err.message }); }
});

// ... (Keep Loops for indexer/buyback) ...
// Note: Buyback loop and Indexer loops are same as before, just ensuring they don't crash if DB locked.

// ... [Copy existing setInterval loops here] ...

app.listen(PORT, () => logger.info(`Server v${VERSION} running on ${PORT}`));
